<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Apuntes de FSIV]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>Apuntes de FSIV</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 29 Oct 2024 15:47:53 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 29 Oct 2024 15:47:49 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[1. Módulo de Adquisición]]></title><description><![CDATA[ 
 <br>En esta sección vamos a conocer los distintos elementos hardware que integran el módulo de adquisición SIVA<br><br>La luz es una&nbsp;onda electromagnética capaz de ser percibida por el ojo humano y cuya frecuencia determina su color.<br>Espectro Visible:<br><img alt="Captura desde 2024-10-26 17-50-36.png" src="añadidos/captura-desde-2024-10-26-17-50-36.png"><br><br>Para poder formar una imagen digital capturada del mundo real, vamos a necesitar los siguientes elementos fundamentales:<br>
<br>Una fuente de Luz: 
<br>Un objeto que reciba la luz, la refleje : 
<br>Un sensor o receptor de la luz: 
<br>Siendo la luz total dentro de un periodo de tiempo acotado:<br><br><img alt="Captura desde 2024-10-26 18-00-57.png" src="añadidos/captura-desde-2024-10-26-18-00-57.png"><br><br>El comportamiento de la luz y la captura de imágenes esta directamente relacionada con las propiedades de los objetos en estas.<br>Propiedades:<br>
<br>Absorbentes: Selectividad del espectro, definen el color del objeto.
<br>Reflexivas: Materiales que reflejan parte de la luz que reciben (Especulares o Difusos).
<br>Transmitivas: El paso de la luz a través de ellos (Ópacos, Translucidos y Transparentes).
<br><img alt="Captura desde 2024-10-26 18-06-08.png" src="añadidos/captura-desde-2024-10-26-18-06-08.png"><br><br>Dentro de la captura de imágenes nos pueden interesar distintos tipos de iluminación en función de los parámetros de la escena.<br>Estas pueden ser Natural, Incandescente, Fluorescentes, Estroboscópica, Láser, LED ...<br>Además de las fuentes de luz se pueden aplicar distintas técnicas.<br>
<br>Direccional: Lateral, Coaxial, Campo Oscuro
<br>Difusa
<br>A contraluz
<br>Iluminación Estructurada
<br><br><br>El modelo de lente fina es una simplificación idealizada del comportamiento óptico de una lente. Este modelo asume que la lente tiene un espesor despreciable y que los rayos de luz pasan a través de un solo plano central.<br>Hay que aclarar que se hace uso de una lente convergente.<br>Se rige por esta fórmula:<br><br>Donde:<br>
<br> es la distancia focal
<br> es la distancia real al objeto
<br> es la distancia en la imagen
<br><img alt="Captura desde 2024-10-26 18-31-23.png" src="añadidos/captura-desde-2024-10-26-18-31-23.png"><br>Vamos a denotan  como la proyección del objeto del mundo real al que le estamos echando la foto y  a la proyección de la imagen. <br>(También hay que aclarar que esta definición es para que yo la entienda mejor puedo no estar bien expresado).<br>A partir de aquí vamos a hablar de algunos parámetros de lente:<br>Distancia focal :<br>La distancia focal es la distancia entre el centro de la lente y el punto donde los rayos de luz paralelos al eje óptico se enfocan (el punto focal).<br>Cuanto menor sea la distancia focal mayor dispersión de la imagen habrá, por lo tanto más borrosa.<br><img alt="Captura desde 2024-10-26 18-41-55.png" src="añadidos/captura-desde-2024-10-26-18-41-55.png"><br>Coeficiente de Magnificación :<br>La magnificación o aumento en una lente fina describe cómo cambia el tamaño del objeto al formar su imagen.<br><br>
<br>Si  entonces la imagen ha aumentado en comparación al objeto del mundo real.
<br>Si  entonces la imagen a disminuido en comparación al objeto del mundo real.
<br>Aquí pondré la deducción matemática de la distancia focal a partir del aumento:<br>Tomamos de referencia esta imagen: <br><img alt="Captura desde 2024-10-26 18-31-23.png" src="añadidos/captura-desde-2024-10-26-18-31-23.png"><br>A partir de los cuales se obtienen 2 triángulos semejantes (Ambos angulos son el mismo).<br><img alt="Captura desde 2024-10-26 20-09-08.png" src="añadidos/captura-desde-2024-10-26-20-09-08.png"><br>Aplicando reglas trigonométricas se obtiene que:<br><br><br>Igualamos:<br><br>Despejamos en función de :<br><br><br> se considera despreciable.<br>Diafragma :<br>
<br>
El diafragma es un mecanismo ajustable dentro del lente de una cámara que regula la cantidad de luz que pasa a través de él. Funciona como un orificio circular cuya apertura puede cambiarse para controlar la intensidad de luz que alcanza el sensor o la película. 

<br>
La apertura se mide en términos del número .

<br>
Control de Luz: Al abrir más el diafragma, entra más luz, y al cerrarlo, entra menos luz.

<br>
Profundidad de Campo: Una apertura mayor (número  menor) genera una profundidad de campo más reducida, enfocando solo una parte de la escena, mientras que una apertura pequeña (número  alto) aumenta la profundidad de campo, manteniendo más elementos de la imagen en foco.

<br>Número  :<br>El número , también llamado relación focal o apertura relativa, es una medida de la apertura del diafragma de la lente, representada con la letra f seguida de un número (como f/2.8, f/5.6, etc.). Este número indica la relación entre la distancia focal del lente y el diámetro efectivo de la apertura:<br>Donde:<br>
<br> es la distancia focal.
<br> es el diámetro de la apertura efectiva del diafragma.
<br>Hay que detallar que  sigue una escala geométrica: <br>Aquí voy a poner algunas aplicaciones de distintos usos de números :<br>
<br>
Retratos: Un número  bajo (f/1.4 o f/2.8) es ideal para retratos, ya que produce un desenfoque de fondo que hace que el sujeto destaque.

<br>
Paisajes: Un número  alto (f/8 o superior) es útil en fotografía de paisajes, donde se necesita una profundidad de campo extensa para mantener todos los elementos en foco.

<br>
Fotografía Nocturna: Usar un número  bajo permite captar más luz, ideal en condiciones de baja iluminación.

<br><img alt="Pasted image 20241026191840.png" src="añadidos/pasted-image-20241026191840.png"><br><br>Dentro de los sensores de cámara podemos distinguir 2 tecnologías muy importantes:<br>
<br>
CCD

<br>
CMOS
CCD (Charge-Coupled Device)

<br>
Funcionamiento: Los sensores CCD convierten la luz en carga eléctrica, que se transfiere a través de la matriz de píxeles a un convertidor analógico-digital (ADC) para formar una imagen.

<br>
Calidad de Imagen: Generalmente, los sensores CCD ofrecen una mejor calidad de imagen en términos de ruido, sensibilidad a la luz y rango dinámico. Esto se debe a su diseño que minimiza el ruido electrónico.

<br>
Sensibilidad a la Luz: Tienen una alta sensibilidad, lo que los hace ideales para fotografía en condiciones de poca luz.

<br>
Consumo de Energía: Consume más energía que los sensores CMOS, lo que puede ser un factor limitante en aplicaciones portátiles.

<br><img alt="Captura desde 2024-10-27 09-07-28.png" src="añadidos/captura-desde-2024-10-27-09-07-28.png"><br> Ventajas<br>
<br>Menos Ruido: Producen imágenes con menos ruido, especialmente en situaciones de baja iluminación.
<br>Alta Calidad de Imagen: Proporcionan una mejor uniformidad en la respuesta del sensor, lo que se traduce en una mayor calidad de imagen.
<br>Desventajas<br>
<br>Costo: Generalmente más caros de producir que los sensores CMOS.
<br>Velocidad: Tienen velocidades de lectura más lentas, lo que puede ser una desventaja en aplicaciones de video de alta velocidad o en captura de imágenes en ráfaga.
<br>Aplicaciones<br>
<br>Usados en cámaras profesionales, telescopios, y aplicaciones científicas donde se requiere alta calidad de imagen.
<br>CMOS (Complementary Metal-Oxide-Semiconductor)<br>Características<br>
<br>
Funcionamiento: Los sensores CMOS utilizan transistores individuales para cada píxel, lo que permite que cada píxel convierta la luz en carga eléctrica y la procese directamente.

<br>
Calidad de Imagen: Aunque han mejorado significativamente en calidad de imagen, los sensores CMOS pueden tener más ruido que los CCD en condiciones de poca luz, aunque esto ha mejorado en modelos recientes.

<br>
Consumo de Energía: Más eficientes en términos de consumo de energía, lo que los hace adecuados para dispositivos portátiles.

<br>
Velocidad: Ofrecen velocidades de lectura más rápidas, lo que es beneficioso para video de alta velocidad y captura de imágenes en ráfaga.

<br><img alt="Captura desde 2024-10-27 09-12-27.png" src="añadidos/captura-desde-2024-10-27-09-12-27.png"><br>Ventajas<br>
<br>
Bajo Costo: Generalmente son más económicos de producir y pueden ser integrados en un solo chip.

<br>
Bajo Consumo de Energía: Tienen un menor consumo energético, lo que es ideal para dispositivos móviles.

<br>
Alta Velocidad: Proporcionan altas velocidades de lectura, útiles para aplicaciones de video.

<br>Desventajas<br>
<br>Más Ruido: Pueden ser más susceptibles al ruido, especialmente en condiciones de poca luz.
<br>Calidad de Imagen Inferior: Aunque han mejorado, en algunas aplicaciones pueden ofrecer una calidad de imagen inferior comparada con los CCD.
<br>Aplicaciones<br>
<br>Usados en cámaras de teléfonos móviles, cámaras digitales de bajo consumo, y en la mayoría de los dispositivos de imagen de bajo costo.
<br><br>Otra comparativa de estas tecnologías es que los dispositivos CMOS tienen menos efecto Blooming o Efecto Halo a diferencia de los CCD, en cambio los CCD tienen menos efector Rolling Shutter<br>Blooming: es un efecto que ocurre principalmente en los sensores CCD. Aparece cuando un píxel se sobresatura al recibir más luz de la que puede manejar, lo que provoca que la carga de ese píxel "rebose" a los píxeles vecinos, generando halos brillantes o áreas sobreexpuestas en la imagen.<br><a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=-DoTgQbALU0" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/watch?v=-DoTgQbALU0" target="_blank">Ejemplo de comparación con <code></code></a>Blooming<br>Rolling Shutter: es un artefacto que aparece principalmente en sensores CMOS. En lugar de capturar toda la imagen a la vez, los sensores CMOS suelen leer cada fila de píxeles de forma secuencial. Esto crea un desfase temporal en la captura de la imagen, lo cual produce distorsiones en objetos en movimiento o en escenas con movimientos rápidos.<br><a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=dNVtMmLlnoE" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/watch?v=dNVtMmLlnoE" target="_blank">Explicación del <code></code></a>Rolling Shutter]]></description><link>1.-módulo-de-adquisición.html</link><guid isPermaLink="false">1. Módulo de Adquisición.md</guid><pubDate>Sun, 27 Oct 2024 10:04:11 GMT</pubDate><enclosure url="añadidos/captura-desde-2024-10-26-17-50-36.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;añadidos/captura-desde-2024-10-26-17-50-36.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2. La Imagen Digital]]></title><description><![CDATA[ 
 <br>En esta sección introduciremos la formación de la imagen y algunos procesos que se aplican a esta.<br><br>Ocurre un problema a la hora de hacer una fotografía y es la siguiente;<br>Lógicamente cuando hacemos una fotografía la hacemos de un objeto de 3 dimensiones con coordenadas , pero una imagen al fin y al cabo es una matriz de filas y columnas es decir se expresan en coordenadas , perder la componente  no es beneficioso.<br>¿Como podría obtener una posición concreta del objeto de la vida real, pero en la imagen?<br>Vamos a representar ambas posiciones en este sistema:<br><br>PONER EXPLICACIÓN<br>Se obtiene que:<br><br><br>Muestreo:<br>
El muestreo es el proceso de convertir una imagen continua en una representación digital. En una imagen continua (como una fotografía), cada punto puede tomar valores precisos de intensidad o color en el espacio continuo. <br>Al digitalizar esta imagen para almacenamiento o procesamiento, se deben tomar muestras en intervalos regulares para obtener una cuadrícula de puntos o píxeles que representan la imagen.<br>
<br>Frecuencia de Muestreo: La frecuencia con la que se toman muestras afecta directamente la calidad de la imagen digital. De acuerdo con el Teorema de Nyquist, la frecuencia de muestreo debe ser al menos el doble de la frecuencia máxima de la imagen (detalle más pequeño) para evitar la pérdida de información.
<br>Resolución de la Imagen: La cantidad de muestras tomadas por unidad de área determina la resolución. Cuanto mayor sea la resolución, más fiel será la representación digital de la imagen continua original.
<br><img alt="Captura desde 2024-10-27 10-05-52.png" src="añadidos/captura-desde-2024-10-27-10-05-52.png"><br> Aliasing en Imágenes:<br>El aliasing ocurre cuando la frecuencia de muestreo es insuficiente para capturar todos los detalles de la imagen continua. Cuando esto sucede, los detalles de alta frecuencia (como líneas finas o texturas detalladas) aparecen distorsionados o producen patrones irreales y no deseados en la imagen digital. Algunos efectos comunes del aliasing incluyen:<br>
<br>Efecto Moiré: Un patrón de interferencia que aparece cuando se superponen patrones repetitivos, como líneas finas, y no se muestrean adecuadamente.
<br>Escalones y Bordes Dentados: Las líneas y curvas aparecen dentadas o en bloques debido a la baja resolución o al muestreo insuficiente, un fenómeno conocido como "aliasing espacial."
<br><img alt="Captura desde 2024-10-27 10-06-17.png" src="añadidos/captura-desde-2024-10-27-10-06-17.png"><br>Ejemplo de Aliasing<br>En una foto de una reja con líneas muy finas, si no se usa la frecuencia de muestreo adecuada, puede aparecer un patrón de interferencia o efecto Moiré en la imagen digital, donde algunas líneas parecen moverse o aparecer duplicadas.<br><img alt="Captura desde 2024-10-27 10-06-35.png" src="añadidos/captura-desde-2024-10-27-10-06-35.png"><br><br>Conversión de energía luminosa a voltaje:<br>
, es un modelo que describe la relación entre la señal de salida de un sensor de imagen (voltaje  ) y la intensidad de luz  que incide sobre el sensor. Cada componente de la ecuación tiene un papel específico:<br>
<br>
: Es el voltaje de salida o la señal generada por el sensor de imagen. Este valor está relacionado con la intensidad luminosa capturada en cada píxel y se convierte finalmente en el valor digital que se representa en la imagen.

<br>
: Es una constante de ganancia que ajusta el nivel de respuesta del sensor a la luz. Aumentar  implica que el sensor responderá más intensamente ante la misma cantidad de luz, amplificando la señal de salida.

<br>
: Es la intensidad de luz que incide sobre el píxel del sensor. Es la variable principal de entrada y representa la cantidad de energía luminosa que el sensor recibe.

<br>
: Es el parámetro de gamma o exponente no lineal que define cómo el sensor responde a diferentes niveles de luz. La gamma modifica la relación entre la luz que incide en el sensor y la señal de salida.

<br>Si , la relación es lineal: la salida del sensor es proporcional a la intensidad de luz .
<br>Si , la respuesta es sub-lineal, lo cual da más importancia a los tonos oscuros y aumenta el detalle en sombras.
<br>Si , la respuesta es sobre-lineal, lo cual aumenta el contraste en las áreas claras.

Este parámetro es importante para ajustar la respuesta del sensor y es común en el procesamiento de imágenes y la corrección gamma en pantallas.

<br>
 : Es un desplazamiento u offset que ajusta el nivel base de la señal, permitiendo que el sensor maneje niveles de luz de fondo o configuraciones de exposición específicas. Este término asegura que el voltaje de salida tenga una referencia o punto de partida adecuado en ausencia de luz (o en condiciones específicas de exposición).

<br><img alt="Captura desde 2024-10-27 10-49-30.png" src="añadidos/captura-desde-2024-10-27-10-49-30.png"><br>Cuantificación:<br>
Una vez que la luz ha sido convertida en voltaje, este valor analógico debe convertirse en un valor digital para que pueda procesarse y almacenarse en dispositivos electrónicos. Aquí es donde entra en juego la cuantificación mediante un convertidor analógico a digital (ADC):<br>
<br>Discretización del Voltaje: El rango de voltajes posibles en el sensor se divide en niveles discretos. Por ejemplo, en una imagen de 8 bits, hay 256 niveles posibles (0 a 255), donde cada nivel representa un rango específico de voltajes.<br>

<br>Asignación de Niveles de Intensidad: El ADC asigna a cada píxel un valor numérico correspondiente al nivel de voltaje que ha medido, generando así una representación digital de la imagen. En una imagen en escala de grises de 8 bits, un valor de 0 representaría negro absoluto (sin luz), y 255 representaría blanco absoluto (máxima intensidad de luz).<br>

<br>Profundidad de Bits: La cantidad de niveles de cuantificación está determinada por la profundidad de bits. A mayor profundidad de bits (por ejemplo, 10 bits o 12 bits), más niveles de intensidad se pueden representar, lo que permite una gama de tonos más amplia y una calidad de imagen más detallada. Sin embargo, esto también implica un mayor uso de almacenamiento y potencia de procesamiento.
<br><br>RGB:<br>
Se basa en representar cualquier color con los 3 colores primarios, en su gama de intensidades. Mejor la que el ordenador lo represente.<br><img alt="Pasted image 20241027105317.png" src="añadidos/pasted-image-20241027105317.png"><br>HSV:<br>
Se basa en función de 3 caracteristicas del color, Hue, Saturation y Value.<br>
Mejor interpretado por el ojo humano.<br><img alt="Pasted image 20241027105331.png" src="añadidos/pasted-image-20241027105331.png"><br><br>Un histograma de una imagen es un gráfico de frecuencias de cada uno de los píxeles de la imagen. <br><img alt="Pasted image 20241027105930.png" src="añadidos/pasted-image-20241027105930.png"><br>
<br>Análisis de Contraste:
<br>
<br>
Un histograma que abarca todo el rango de intensidades (desde el negro hasta el blanco) indica una buena distribución del contraste.

<br>
Un histograma concentrado en un extremo sugiere que la imagen podría estar subexpuesta (concentrado a la izquierda) o sobreexpuesta (concentrado a la derecha).

<br>
<br>Ecualización de Histogramas:
<br>
<br>
Este es un método para mejorar el contraste de una imagen al redistribuir los niveles de intensidad.

<br>
Al ecualizar un histograma, se busca que la distribución de los píxeles se extienda a través de todo el rango disponible, lo que resulta en una imagen con mayor contraste y más detalles.

<br>Clasificación de imágenes según su histograma<br>
<br>
Imagen Subexpuesta:<br>
Histograma concentrado a la izquierda, indicando que la mayoría de los píxeles son oscuros.

<br>
Imagen Sobreexpuesta:<br>
Histograma concentrado a la derecha, mostrando que la mayoría de los píxeles son claros.

<br>
Imagen Bien Expuesta:<br>
Histograma que abarca un rango amplio desde la izquierda hasta la derecha, indicando una buena distribución de tonos.

<br><img alt="Captura desde 2024-10-27 11-00-48.png" src="añadidos/captura-desde-2024-10-27-11-00-48.png">]]></description><link>2.-la-imagen-digital.html</link><guid isPermaLink="false">2. La Imagen Digital.md</guid><pubDate>Sun, 27 Oct 2024 10:00:55 GMT</pubDate><enclosure url="añadidos/captura-desde-2024-10-27-10-05-52.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;añadidos/captura-desde-2024-10-27-10-05-52.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3. Procesado de la Imagen Digital]]></title><description><![CDATA[ 
 <br>En esta sección hablaremos de algunas técnicas de procesado de la imagen;<br>
en el Dominio Espacial en concreto puntual o con varias imágenes y basado en la vecindad.<br>Antes de comenzar me gustaría aclarar el concepto de Rango Dinámico de una imagen.<br>
<br>
En el contexto de la iluminación en fotografía, el rango dinámico se refiere a la capacidad de captar el detalle en las luces y sombras dentro de una misma imagen. 

<br>
Es la diferencia entre el nivel de luz más intenso y el más débil que una cámara puede capturar sin perder detalles.

<br><br>Normalización del Rango Dinámico:<br>Esta técnica puede ser interesante si se quiere: <br>
<br>Obtener un aumento del contraste para resaltar los detalles tanto de las sombras como de las luces, para tener una imagen más equlibrada y agradable.
<br>Mejora la claridad de la imagen.
<br>Puede mejorar la compatibilidad entre dispositivos con distinto rango dinámico.
<br>Trabajaremos 2 técnicas:<br>Normalización Lineal: Queremos reducir o expandir el rango dinámico.<br><br><br>Normalización de Media y Varianza:<br><br><br>Si fuera a la normal , sería:<br><br>Ajuste de gamma, contraste y brillo:<br>No hay mucho que comentar de esta técnica, mediante una operación píxel a píxel modifica la gamma, constraste y brillo.<br>¿Que es la gamma?<br>La gamma se refiere a un parámetro que describe la relación no lineal entre la intensidad de luz que se muestra en una pantalla (o se captura por un sensor) y la intensidad de luz real (o la señal de entrada). En otras palabras, la gamma define cómo se transforma la señal de voltaje en luminancia percibida.<br><br>
<br>Si , la relación es lineal: la salida del sensor es proporcional a la intensidad de luz .
<br>Si , la respuesta es sub-lineal, lo cual da más importancia a los tonos oscuros y aumenta el detalle en sombras.
<br>Si , la respuesta es sobre-lineal, lo cual aumenta el contraste en las áreas claras.
<br>Ecualización:<br>Esta técnica lo que busca hacer es que a partir del histograma de una imagen, se obtiene su histograma normalizado y acumulado y después aplicar una transformación de los píxeles de este histograma a la imagen real.<br>Esto se hace ya que este histograma esta mucho mejor repartido, se podría decir que sería el histograma de la imagen ideal a la original, ya que no estara ni sobreexpuesta ni subexpuesta.<br><img alt="Captura desde 2024-10-27 11-56-20.png" src="añadidos/captura-desde-2024-10-27-11-56-20.png"><br>LookUp Table:<br>Estas tablas básicamente, para aplicar una conversión de un píxel a otro dentro de una imagen, cada píxel tiene su transformación asociada, normalmente precalculada con el procesamiento que se le quiera aplicar.<br>Las lookup tables hacen mucho más eficiente el procesamiento de la imagen ya que no se tendrá que calcular la operación píxel a píxel de la imagen, ya que ya están precalculadas. <br>Un ejemplo muy sencillo es la inversión de una imagen a cada pixel se aplica , pero al estar precalculado es más eficiente.<br>Cambios de espacio de Color:<br>Los dos sistemas de color que hemos usado han sido por ahora RGB y HSV, es por eso que nos interesa poder cambiar entre estos, por ejemplo si queremos hacer una aplicación que aplique Chroma Key nos interesa cambiar al espacio de color HSV para tener el rango de colores del cual deseamos crear la máscara.<br>Balanceo de Color:<br>Trabajamos 2 técnicas: White Patch y Gray World.<br>La primera técnica White Patch, consiste en que el punto más blanco de una imagen debe ser el blanco, dependiendo de algunos parámetros lo que se suele hacer es buscar el punto más brillante de la imagen y reescalar esta para que el punto más brillante sea e blanco, otras versiones y para evitar blancos quemados, se usa la media se los p% puntos menos brillante.<br>En el caso del Gray World, lo que queremos obtener es neutralizar los dominantes de color, haciendo una imagen más neutra (más cercana al gris), de nuevo aplicando un reescalado.<br><br>
<br>
Suma: La suma de numerosas imágenes iguales con ruido hace que la imagen, gane nitidez.

<br>
Resta: Sirve principalmente para detectar movimientos en planos estáticos, si hacemos la diferencia de dos fotos de la misma escena y algo se ha movido, la diferencia saldrá todo en negro (0) menos la silueta del elemento distinto.

<br>
Multiplicación/División: pueden servir para reducir iluminaciones no deseadas dividiendo  imágenes mal iluminadas entre una imagen tipo que represente los tonos de luz que no queremos.

<br>
Operaciones Lógicas: Útiles para la composición de imágenes.

]]></description><link>3.-procesado-de-la-imagen-digital.html</link><guid isPermaLink="false">3. Procesado de la Imagen Digital.md</guid><pubDate>Sun, 27 Oct 2024 11:21:39 GMT</pubDate><enclosure url="añadidos/captura-desde-2024-10-27-11-56-20.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;añadidos/captura-desde-2024-10-27-11-56-20.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4. Procesado Basado en la Vecindad]]></title><description><![CDATA[ 
 <br>En el procesamiento de imágenes, la vecindad de un píxel se refiere al conjunto de píxeles circundantes que rodean a un píxel central específico dentro de una imagen. <br>Estos píxeles vecinos son considerados cuando se aplican ciertos filtros y operaciones de procesamiento de imágenes que dependen del contexto local de cada píxel, como en operaciones de suavizado, detección de bordes y reducción de ruido.<br><br>La interpolación es una técnica para estimar valores de píxeles en posiciones que no coinciden con un píxel exacto de la imagen original. Es útil en operaciones como cambio de tamaño, rotación y distorsión de imágenes. <br>A continuación, se presentan tres métodos comunes: Vecino Más Cercano (NN), Bilineal y Bicúbica.<br>Vecino Más Cercano (Nearest Neighbor - NN):<br>Este es el método más simple y rápido, que asigna a un píxel el valor del píxel más cercano de la imagen original.<br>
<br>Método: Se busca el píxel en la imagen original más cercano a la posición en la imagen de salida y se asigna su valor al píxel de salida.
<br>Ventajas: Muy rápido y eficiente en cuanto a cómputo.
<br>Desventajas: Produce bordes "escalonados" o pixelados debido a la falta de suavidad entre píxeles.
<br>Aplicaciones: Útil en aplicaciones donde la velocidad es prioritaria, como en visualización rápida o en segmentación de imágenes.
<br><img alt="Captura desde 2024-10-27 21-21-48.png" src="añadidos/captura-desde-2024-10-27-21-21-48.png"><br>Interpolación Bilineal:<br>La interpolación bilineal considera no solo el píxel más cercano, sino también los píxeles vecinos inmediatos en direcciones horizontales y verticales. Calcula el valor del píxel de salida como una combinación ponderada de estos cuatro píxeles.<br>
<br>
Método:

<br>Encuentra los cuatro píxeles vecinos de la posición en la imagen original.
<br>Realiza interpolaciones lineales en las direcciones horizontal y vertical, promediando los valores según la distancia.


<br>
Ventajas: Transiciones más suaves entre píxeles, lo que reduce el efecto de pixelado.

<br>
Desventajas: Requiere más cálculos, lo cual puede aumentar el tiempo de procesamiento.

<br>
Aplicaciones: Ideal para redimensionamiento y rotación donde se busca mejorar la calidad visual sin mucha carga de procesamiento.

<br><img alt="Captura desde 2024-10-27 21-22-27.png" src="añadidos/captura-desde-2024-10-27-21-22-27.png"><br>Interpolación Bicúbica:<br>Este método avanzado usa 16 píxeles vecinos (4x4) y se basa en funciones cúbicas para transiciones más suaves y precisas.<br>
<br>
Método:

<br>Toma un bloque de 4x4 píxeles alrededor del píxel de interés.
<br>Calcula interpolación cúbica en cada dirección (horizontal y vertical) para una estimación precisa del píxel de salida.


<br>
Ventajas: Alta calidad visual, con transiciones muy suaves, ideal para imágenes con detalles finos.

<br>
Desventajas: Es el método más lento de los tres debido al número de cálculos necesarios, y puede introducir artefactos de suavizado.

<br>
Aplicaciones: Usado en aplicaciones donde se prioriza la calidad de imagen, como en edición de fotografías, impresión de alta calidad y gráficos computacionales.

<br><img alt="Captura desde 2024-10-27 21-23-02.png" src="añadidos/captura-desde-2024-10-27-21-23-02.png"><br><br><img alt="Captura desde 2024-10-27 21-23-25.png" src="añadidos/captura-desde-2024-10-27-21-23-25.png"><br>
<img alt="Captura desde 2024-10-27 21-23-51.png" src="añadidos/captura-desde-2024-10-27-21-23-51.png"><br><br>Correlación:<br><br>Básicamente por cada píxel de la imagen, extraemos una parcela del tamaño del filtro, multiplicamos en cada píxel de la parcela lo valores del filtro y suma esos valores al píxel en el que estamos trabajando.<br>Donde:<br>
 : es la imagen resultado.<br>
 : es la imagen de entrada.<br>
 : es el filtro.<br>La correlación se utiliza para buscar patrones y coincidencias.<br>Convolución:<br><br>Hacemos la misma operación que con la correlación solo que el filtro esta rotado 180º.<br>La convolución se suele aplicar  como desenfoque, detección de bordes y suavizado.<br>Vamos a ver algunos tipos de filtros lineales.<br>Filtro Paso Baja (Box Filter):<br><br>Bloquea las altas frecuencias para quedarnos con un resultado<br>
suavizado, con estructuras principales y sin detalles.<br>Filtro Paso Baja (Gaussian Filter):<br><br><br>Mismo objetivo que el anterior. Le da más importancia a los píxeles que comparten aristas con el seleccionado a estudio que a las diagonales. <br>Utiliza una distribución gaussiana con una constante  a elegir. <br>A mayor  la imagen obtenida es de más baja frecuencia.<br><img alt="Captura desde 2024-10-28 02-01-02.png" src="añadidos/captura-desde-2024-10-28-02-01-02.png"><br>Realce de Imagen (Unsharp Mask):<br>El Unsharp Mask (máscara de enfoque) es una técnica utilizada en el procesamiento de imágenes para mejorar la nitidez de una imagen. <br>A pesar de su nombre, el unsharp mask no hace que una imagen se vea menos nítida; en realidad, aumenta la claridad de los bordes y los detalles, creando la ilusión de que la imagen es más nítida.<br>Realiza la siguiente operación:<br><br>o también:<br><br>Donde:<br>
 : es la imagen de salida enfocada.<br>
 : es la imagen original.<br>
 : es un coeficiente que si es mayor que 1 se denomina high-boost-filtering.<br>
 : imagen desenfocada o suavizada.<br>A mayor  mayor enfoque.<br><img alt="Captura desde 2024-10-28 02-14-30.png" src="añadidos/captura-desde-2024-10-28-02-14-30.png"><br>Filtros Paso Alta (Derivadas de la imagen):<br>Las derivadas de una imagen son herramientas fundamentales en el procesamiento de imágenes, ya que permiten medir el cambio de intensidad en diferentes direcciones.<br>Esto es especialmente útil para detectar bordes, que son transiciones rápidas en la intensidad de píxeles.<br>La primera derivada indica el cambio de intensidad en el eje <br><br>
<br>Cero en las zonas constantes
<br>Distinto de cero en el escalón o comienzo/fin de rampas
<br>No cero durante la rampa
<br>Kernel para primera derivada:<br><br>La segunda derivada da información de la curvatura de la intensidad.<br><br>
<br>Cero en las zonas constantes
<br>Distinto de cero en las zonas de comienzo/fin de rampa
<br>Cero durante la rampa
<br>Kernel para segunda derivada:<br><br><img alt="Captura desde 2024-10-28 02-23-38.png" src="añadidos/captura-desde-2024-10-28-02-23-38.png"><br>Filtros Paso Alta (Filtro Sobel):<br>El filtro Sobel es una técnica comúnmente utilizada en el procesamiento de imágenes para la detección de bordes. <br>Se basa en calcular la derivada de la intensidad de la imagen en direcciones específicas (horizontal y vertical) para resaltar los cambios abruptos en la intensidad de los píxeles.<br>¿Como funciona?<br>El filtro Sobel utiliza dos matrices de convolución (kernels) que se aplican a la imagen para calcular la magnitud y la dirección del gradiente de la intensidad de la imagen.<br>Estas matrices están diseñadas para resaltar bordes y cambios de intensidad en las direcciones horizontal y vertical.<br><br><br>La magnitud del gradiente se puede calcular con:<br><br>Filtros Paso Alta (Laplaciano):<br>El operador Laplaciano es un filtro utilizado en el procesamiento de imágenes para detectar bordes y cambios abruptos en la intensidad de una imagen. <br>Se puede considerar un operador de paso alto porque realza las áreas donde hay cambios significativos, mientras que suprime las áreas donde la intensidad es constante.<br>Se representa con:<br><br>Sus kernels más representativos son:<br><br>Esta es otra representación que resalta los bordes de manera más intensa:<br><br>Realce de Imagen (Sharpenning):<br>El realce de imágenes o sharpening es un conjunto de técnicas utilizadas para mejorar la claridad y definición de los detalles en una imagen. <br>El objetivo principal del sharpening es resaltar los bordes y otros detalles significativos, haciendo que la imagen parezca más nítida.<br>Sus kernels más representativos:<br>Este kernel realza el píxel central mientras suprime los píxeles vecinos.<br><br>Este kernel es más agresivo en la detección de bordes.<br><br>Se deducen estos kernels de la siguiente interpretación del sharpenning:<br><br><br>En el filtrado no lineal, el valor de cada píxel se calcula mediante una operación no lineal basada en los valores de los píxeles vecinos, lo que permite resultados más adaptativos y robustos para ciertos tipos de ruido<br>Filtro por Mediana:<br>Sustituye el valor de cada píxel por la mediana de los valores de su vecindad.<br>Es especialmente útil para eliminar el ruido impulsivo o también llamado ruido de sal y pimienta.<br><img alt="Captura desde 2024-10-28 03-15-03.png" src="añadidos/captura-desde-2024-10-28-03-15-03.png"><br>Filtro Bilateral:<br>El filtro bilateral es un tipo de filtro no lineal que se utiliza en el procesamiento de imágenes para suavizar áreas sin afectar significativamente los bordes. Es muy popular para reducir el ruido en las imágenes, especialmente cuando se quiere preservar los detalles y bordes importantes.<br>A diferencia de otros filtros de suavizado, el filtro bilateral no solo considera la cercanía espacial de los píxeles, sino también la similitud de intensidad entre los píxeles vecinos, lo cual le permite diferenciar entre áreas con variación de intensidad gradual (como el interior de un objeto) y bordes definidos (donde hay un cambio brusco de intensidad).<br><br><img alt="Captura desde 2024-10-28 03-21-55.png" src="añadidos/captura-desde-2024-10-28-03-21-55.png"><br>Morfología (Operadores):<br>La erosión es un operador que reduce el tamaño de los objetos en la imagen. El objetivo es "erosionar" las fronteras de los objetos, lo que reduce el ruido y separa objetos que están ligeramente conectados.<br>
<br>
Definición: La erosión de una imagen  por un elemento estructurante  consiste en reducir las zonas de intensidad alta (blancas) en la imagen. En una imagen binaria, un píxel permanecerá en el valor alto (1 o blanco) solo si todos los píxeles de la vecindad definida por el elemento estructurante también son 1. Si algún píxel en la vecindad es 0 (negro), entonces el píxel central se convertirá en 0.

<br>
Efecto Visual: La erosión tiende a adelgazar las áreas blancas de la imagen y a eliminar pequeñas regiones y ruidos aislados.

<br>La dilatación es el operador opuesto a la erosión. En este caso, se expanden las áreas de intensidad alta (blancas) en la imagen. Este operador es útil para rellenar huecos en objetos, unir componentes vecinos y agrandar objetos en la imagen.<br>
<br>Definición: La dilatación de una imagen  por un elemento estructurante  consiste en expandir las zonas de intensidad alta (blancas). En una imagen binaria, un píxel se convierte en 1 si algún píxel en la vecindad definida por el elemento estructurante es 1.<br>

<br>Efecto Visual: La dilatación aumenta el tamaño de las áreas blancas y tiende a unir pequeñas regiones que están próximas, rellenando espacios entre objetos.
<br>En definitiva y lo importante que te tienes que quedar, es que en la dilatación te quedas con el píxel activo más grande y en la erosión con el más pequeño.<br><img alt="Captura desde 2024-10-28 03-28-51.png" src="añadidos/captura-desde-2024-10-28-03-28-51.png"><br>]]></description><link>4.-procesado-basado-en-la-vecindad.html</link><guid isPermaLink="false">4. Procesado Basado en la Vecindad.md</guid><pubDate>Tue, 29 Oct 2024 07:53:51 GMT</pubDate><enclosure url="añadidos/captura-desde-2024-10-27-21-21-48.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;añadidos/captura-desde-2024-10-27-21-21-48.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5. Modelo Pin-Hole]]></title><description><![CDATA[ 
 ]]></description><link>5.-modelo-pin-hole.html</link><guid isPermaLink="false">5. Modelo Pin-Hole.md</guid><pubDate>Tue, 29 Oct 2024 08:03:25 GMT</pubDate></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br><a data-href="1. Módulo de Adquisición" href="1.-módulo-de-adquisición.html" class="internal-link" target="_self" rel="noopener nofollow">1. Módulo de Adquisición</a><br>
<a data-href="2. La Imagen Digital" href="2.-la-imagen-digital.html" class="internal-link" target="_self" rel="noopener nofollow">2. La Imagen Digital</a><br>
<a data-href="3. Procesado de la Imagen Digital" href="3.-procesado-de-la-imagen-digital.html" class="internal-link" target="_self" rel="noopener nofollow">3. Procesado de la Imagen Digital</a><br>
<a data-href="4. Procesado Basado en la Vecindad" href="4.-procesado-basado-en-la-vecindad.html" class="internal-link" target="_self" rel="noopener nofollow">4. Procesado Basado en la Vecindad</a>]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Sun, 27 Oct 2024 23:03:38 GMT</pubDate></item></channel></rss>